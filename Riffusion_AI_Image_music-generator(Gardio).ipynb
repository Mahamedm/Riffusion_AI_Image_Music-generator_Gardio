{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Riffusion AI music generator(Gardio)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0zja506vn3cH"
      },
      "source": [
        "## Credit to [Riffusion](https://github.com/hmartiro/riffusion-inference) and [Amrrs](https://github.com/amrrs/ai-music-video) project.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using google colab to use this notebook is highly recommended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkHln1zloZi0"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LSXMhbyn3cB"
      },
      "source": [
        "# Install Following Libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGsoykl0DG5A"
      },
      "outputs": [],
      "source": [
        "!pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-12-16T05:15:35.086025Z",
          "iopub.status.busy": "2022-12-16T05:15:35.085587Z",
          "iopub.status.idle": "2022-12-16T05:15:48.231336Z",
          "shell.execute_reply": "2022-12-16T05:15:48.230116Z",
          "shell.execute_reply.started": "2022-12-16T05:15:35.085938Z"
        },
        "id": "Wj4jwce7n3cE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "! pip install -U transformers diffusers gradio ftfy pydub -q "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-16T05:16:04.797495Z",
          "iopub.status.busy": "2022-12-16T05:16:04.797083Z",
          "iopub.status.idle": "2022-12-16T05:16:06.118679Z",
          "shell.execute_reply": "2022-12-16T05:16:06.117578Z",
          "shell.execute_reply.started": "2022-12-16T05:16:04.797457Z"
        },
        "id": "gwu744bZn3cI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Audio processing tools to convert between spectrogram images and waveforms.\n",
        "\"\"\"\n",
        "import io\n",
        "import typing as T\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pydub\n",
        "from scipy.io import wavfile\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "\n",
        "def wav_bytes_from_spectrogram_image(image: Image.Image) -> T.Tuple[io.BytesIO, float]:\n",
        "    \"\"\"\n",
        "    Reconstruct a WAV audio clip from a spectrogram image. Also returns the duration in seconds.\n",
        "    \"\"\"\n",
        "\n",
        "    max_volume = 50\n",
        "    power_for_image = 0.25\n",
        "    Sxx = spectrogram_from_image(image, max_volume=max_volume, power_for_image=power_for_image)\n",
        "\n",
        "    sample_rate = 44100  # [Hz]\n",
        "    clip_duration_ms = 5000  # [ms] (duration fixed at 5.11 sec)\n",
        "\n",
        "    bins_per_image = 512\n",
        "    n_mels = 512\n",
        "\n",
        "    # FFT parameters\n",
        "    window_duration_ms = 100  # [ms]\n",
        "    padded_duration_ms = 400  # [ms]\n",
        "    step_size_ms = 10  # [ms]\n",
        "\n",
        "    # Derived parameters\n",
        "    num_samples = int(image.width / float(bins_per_image) * int(clip_duration_ms)) * sample_rate\n",
        "\n",
        "    print(image.width / float(bins_per_image))\n",
        "\n",
        "    n_fft = int(padded_duration_ms / 1000.0 * sample_rate)\n",
        "    hop_length = int(step_size_ms / 1000.0 * sample_rate)\n",
        "    win_length = int(window_duration_ms / 1000.0 * sample_rate)\n",
        "\n",
        "    samples = waveform_from_spectrogram(\n",
        "        Sxx=Sxx,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        win_length=win_length,\n",
        "        num_samples=num_samples,\n",
        "        sample_rate=sample_rate,\n",
        "        mel_scale=True,\n",
        "        n_mels=n_mels,\n",
        "        max_mel_iters=200,\n",
        "        num_griffin_lim_iters=32,\n",
        "    )\n",
        "\n",
        "    wav_bytes = io.BytesIO()\n",
        "    wavfile.write(wav_bytes, sample_rate, samples.astype(np.int16))\n",
        "    wav_bytes.seek(0)\n",
        "\n",
        "    duration_s = float(len(samples)) / sample_rate\n",
        "\n",
        "    return wav_bytes, duration_s\n",
        "\n",
        "\n",
        "def spectrogram_from_image(\n",
        "    image: Image.Image, max_volume: float = 50, power_for_image: float = 0.25\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute a spectrogram magnitude array from a spectrogram image.\n",
        "    \"\"\"\n",
        "    # Convert to a numpy array of floats\n",
        "    data = np.array(image).astype(np.float32)\n",
        "\n",
        "    # Flip Y take a single channel\n",
        "    data = data[::-1, :, 0]\n",
        "\n",
        "    # Invert\n",
        "    data = 255 - data\n",
        "\n",
        "    # Rescale to max volume\n",
        "    data = data * max_volume / 255 \n",
        "\n",
        "    # Reverse the power curve\n",
        "    data = np.power(data, 1 / power_for_image)\n",
        "\n",
        "    return data\n",
        "\n",
        "def image_from_spectrogram(\n",
        "    spectrogram: np.ndarray, max_volume: float = 50, power_for_image: float = 0.25\n",
        ") -> Image.Image:\n",
        "    \"\"\"\n",
        "    Compute a spectrogram image from a spectrogram magnitude array.\n",
        "    \"\"\"\n",
        "    # Apply the power curve\n",
        "    data = np.power(spectrogram, power_for_image)\n",
        "\n",
        "    # Rescale to 0-1\n",
        "    data = data / np.max(data)\n",
        "\n",
        "    # Rescale to 0-255\n",
        "    data = data * 255\n",
        "\n",
        "    # Invert\n",
        "    data = 255 - data\n",
        "\n",
        "    # Convert to a PIL image\n",
        "    image = Image.fromarray(data.astype(np.uint8))\n",
        "\n",
        "    # Flip Y\n",
        "    image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "\n",
        "    # Convert to RGB\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    return image\n",
        "\n",
        "def spectrogram_from_waveform(\n",
        "    waveform: np.ndarray,\n",
        "    sample_rate: int,\n",
        "    n_fft: int,\n",
        "    hop_length: int,\n",
        "    win_length: int,\n",
        "    mel_scale: bool = True,\n",
        "    n_mels: int = 512,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute a spectrogram from a waveform.\n",
        "    \"\"\"\n",
        "\n",
        "    spectrogram_func = torchaudio.transforms.Spectrogram(\n",
        "        n_fft=n_fft,\n",
        "        power=None,\n",
        "        hop_length=hop_length,\n",
        "        win_length=win_length,\n",
        "    )\n",
        "\n",
        "    waveform_tensor = torch.from_numpy(waveform.astype(np.float32)).reshape(1, -1)\n",
        "    Sxx_complex = spectrogram_func(waveform_tensor).numpy()[0]\n",
        "\n",
        "    Sxx_mag = np.abs(Sxx_complex)\n",
        "\n",
        "    if mel_scale:\n",
        "        mel_scaler = torchaudio.transforms.MelScale(\n",
        "            n_mels=n_mels,\n",
        "            sample_rate=sample_rate,\n",
        "            f_min=0,\n",
        "            f_max=10000,\n",
        "            n_stft=n_fft // 2 + 1,\n",
        "            norm=None,\n",
        "            mel_scale=\"htk\",\n",
        "        )\n",
        "\n",
        "        Sxx_mag = mel_scaler(torch.from_numpy(Sxx_mag)).numpy()\n",
        "\n",
        "    return Sxx_mag\n",
        "\n",
        "\n",
        "def waveform_from_spectrogram(\n",
        "    Sxx: np.ndarray,\n",
        "    n_fft: int,\n",
        "    hop_length: int,\n",
        "    win_length: int,\n",
        "    num_samples: int,\n",
        "    sample_rate: int,\n",
        "    mel_scale: bool = True,\n",
        "    n_mels: int = 512,\n",
        "    max_mel_iters: int = 200,\n",
        "    num_griffin_lim_iters: int = 32,\n",
        "    device: str = \"cuda:0\",\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Reconstruct a waveform from a spectrogram.\n",
        "    This is an approximate inverse of spectrogram_from_waveform, using the Griffin-Lim algorithm\n",
        "    to approximate the phase.\n",
        "    \"\"\"\n",
        "    Sxx_torch = torch.from_numpy(Sxx).to(device)\n",
        "\n",
        "    if mel_scale:\n",
        "        mel_inv_scaler = torchaudio.transforms.InverseMelScale(\n",
        "            n_mels=n_mels,\n",
        "            sample_rate=sample_rate,\n",
        "            f_min=0,\n",
        "            f_max=10000,\n",
        "            n_stft=n_fft // 2 + 1,\n",
        "            norm=None,\n",
        "            mel_scale=\"htk\",\n",
        "            max_iter=max_mel_iters,\n",
        "        ).to(device)\n",
        "\n",
        "        Sxx_torch = mel_inv_scaler(Sxx_torch)\n",
        "\n",
        "    griffin_lim = torchaudio.transforms.GriffinLim(\n",
        "        n_fft=n_fft,\n",
        "        win_length=win_length,\n",
        "        hop_length=hop_length,\n",
        "        power=1.0,\n",
        "        n_iter=num_griffin_lim_iters,\n",
        "    ).to(device)\n",
        "\n",
        "    waveform = griffin_lim(Sxx_torch).cpu().numpy()\n",
        "\n",
        "    return waveform\n",
        "\n",
        "\n",
        "def mp3_bytes_from_wav_bytes(wav_bytes: io.BytesIO) -> io.BytesIO:\n",
        "    mp3_bytes = io.BytesIO()\n",
        "    sound = pydub.AudioSegment.from_wav(wav_bytes)\n",
        "    sound.export(mp3_bytes, format=\"mp3\")\n",
        "    mp3_bytes.seek(0)\n",
        "    return mp3_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZqPyj89n3cI"
      },
      "source": [
        "# Import all required Libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-16T05:16:06.121995Z",
          "iopub.status.busy": "2022-12-16T05:16:06.121569Z",
          "iopub.status.idle": "2022-12-16T05:16:19.648726Z",
          "shell.execute_reply": "2022-12-16T05:16:19.647614Z",
          "shell.execute_reply.started": "2022-12-16T05:16:06.121953Z"
        },
        "id": "J-ieJxc6n3cJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tvKNPYHn3cK"
      },
      "source": [
        "# Load the model from Hugging Face Model Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8iL5ERqEC_r"
      },
      "outputs": [],
      "source": [
        "model_id = \"riffusion/riffusion-model-v1\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-16T05:16:19.651382Z",
          "iopub.status.busy": "2022-12-16T05:16:19.650511Z",
          "iopub.status.idle": "2022-12-16T05:18:42.184284Z",
          "shell.execute_reply": "2022-12-16T05:18:42.183131Z",
          "shell.execute_reply.started": "2022-12-16T05:16:19.651343Z"
        },
        "id": "Gmc3nzz0n3cK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mfSlMC7n3cM"
      },
      "source": [
        "# Create the core Audio Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "we766yd4FzJk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "COLORS = [\n",
        "    [\"#ff0000\", \"#00ff00\"],\n",
        "    [\"#00ff00\", \"#0000ff\"],\n",
        "    [\"#0000ff\", \"#ff0000\"],\n",
        "]    \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apg64U15Gaqe"
      },
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "img_model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "img_pipe = StableDiffusionPipeline.from_pretrained(img_model_id, torch_dtype=torch.float16, revision=\"fp16\")\n",
        "img_pipe = img_pipe.to(\"cuda\")\n",
        "img_pipe.enable_xformers_memory_efficient_attention()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "qhNrdf9aJGj2"
      },
      "outputs": [],
      "source": [
        "# Rejects nfsw prompts. If any found retry another description.\n",
        "prompt = 'skeleton man in a basement in ohio'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY_eUTvHJJgZ"
      },
      "outputs": [],
      "source": [
        "# generate WAV file\n",
        "spectogram = pipe(prompt).images[0]\n",
        "wav = wav_bytes_from_spectrogram_image(spectogram)\n",
        "with open(\"output.wav\", \"wb\") as f:\n",
        "    # print(wav[1])\n",
        "    f.write(wav[0].getbuffer())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxkxAn4RMGiO"
      },
      "outputs": [],
      "source": [
        "image = img_pipe(prompt + \", photo realsitic, emotionally evocative, a thing of beauty beyond imagination or words\").images[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYJkrWlxMthJ"
      },
      "outputs": [],
      "source": [
        "image #sample view image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "6XWYDY3LJS0-"
      },
      "outputs": [],
      "source": [
        "image.save(\"image.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "QX6vX4IkGHDx"
      },
      "outputs": [],
      "source": [
        "video_path = gr.make_waveform('output.wav', bg_image='image.png', bars_color=random.choice(COLORS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GLxF4mILUgq"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        " \n",
        "def show_video(video_path, video_width = 600):\n",
        "   \n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        " \n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        " \n",
        "show_video(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-16T05:18:42.187453Z",
          "iopub.status.busy": "2022-12-16T05:18:42.185807Z",
          "iopub.status.idle": "2022-12-16T05:18:42.193673Z",
          "shell.execute_reply": "2022-12-16T05:18:42.192509Z",
          "shell.execute_reply.started": "2022-12-16T05:18:42.187411Z"
        },
        "id": "1LXKC_UMn3cM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def audio_gen(prompt):\n",
        "    spectogram = pipe(prompt).images[0]\n",
        "    wav = wav_bytes_from_spectrogram_image(spectogram)\n",
        "    with open(\"output.wav\", \"wb\") as f:\n",
        "        f.write(wav[0].getbuffer())\n",
        "    print(\"audio saved\")\n",
        "    print(\"image started\")\n",
        "    txt_prompt = prompt + \", artstation hall of fame gallery, editors choice, #1 digital painting of all time, most beautiful image ever created, emotionally evocative, greatest art ever made, lifetime achievement magnum opus masterpiece, the most amazing breathtaking image with the deepest message ever painted, a thing of beauty beyond imagination or words\"\n",
        "    image = img_pipe(txt_prompt).images[0] \n",
        "    image.save(\"image.png\") \n",
        "    print(\"image saved\")\n",
        "    video = gr.make_waveform('output.wav', bg_image='image.png', bars_color=random.choice(COLORS))\n",
        "    print(\"video done!\")\n",
        "    return ('output.wav',video)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPFDlFZ2Nd3P"
      },
      "outputs": [],
      "source": [
        "audio_gen(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAdjLnCHRGSV"
      },
      "outputs": [],
      "source": [
        "# gardio interface hosted locally\n",
        "gr.Interface(\n",
        "    audio_gen,\n",
        "    inputs=[gr.Textbox(label=\"prompt\")],\n",
        "    outputs=[\n",
        "        gr.Audio(type='filepath'),\n",
        "        gr.Video(type='filepath')\n",
        "    ],\n",
        "    title = 'Riffusion Music Page'\n",
        ").launch(debug = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
